window.quizData = {
    title: "4-（６）生成モデル：VAE, GAN, 拡散モデル",
    
    cheatSheet: `
        <h3>■ 識別モデル vs 生成モデル</h3>
        <ul>
            <li><strong>識別モデル</strong> ($P(y|x)$): 入力 $x$ からラベル $y$ を予測（分類など）。</li>
            <li><strong>生成モデル</strong> ($P(x)$): データ $x$ そのものの分布を学習し、新しいデータを生成する。</li>
        </ul>

        <h3>■ 代表的な生成モデル</h3>
        <table>
            <tr><th>モデル</th><th>仕組み</th><th>特徴</th></tr>
            <tr><td><strong>VAE</strong><br>(変分オートエンコーダ)</td><td>入力 → <strong>潜在変数 $z$ (確率分布)</strong> → 再構成。<br>ロス = 再構成誤差 + <strong>KLダイバージェンス</strong>。</td><td>画像が少しぼやけやすい。<br>数学的に扱いやすい。</td></tr>
            <tr><td><strong>GAN</strong><br>(敵対的生成NW)</td><td><strong>G (生成器)</strong> vs <strong>D (識別器)</strong> の競争。<br>Minimaxゲームを行う。</td><td>くっきりした画像が作れる。<br>学習が不安定（モード崩壊）。</td></tr>
            <tr><td><strong>拡散モデル</strong><br>(Diffusion)</td><td>画像にノイズを徐々に加え(拡散)、それを逆再生(除去)する過程を学習。</td><td>生成が高品質で多様。<br>生成（推論）に時間がかかる。</td></tr>
        </table>

        <h3>■ 重要キーワード</h3>
        <ul>
            <li><strong>Reparameterization Trick</strong>: VAEで確率的なサンプリングをしつつ、誤差逆伝播（微分）を可能にする式変形。</li>
            <li><strong>モード崩壊 (Mode Collapse)</strong>: GANが特定のパターンの画像しか生成しなくなってしまう現象。</li>
        </ul>
    `,

    questions: [
        // ---------------------------------------------------------
        // 【基礎編】 Q1 - Q10
        // ---------------------------------------------------------
        {
            category: "基本概念",
            question: "「生成モデル」と「識別モデル」の違いについて、正しい記述はどれか。",
            options: ["識別モデルはデータからラベルを予測する条件付き確率 $P(y|x)$ を学ぶが、生成モデルはデータの分布 $P(x)$ そのものを学ぶ", "生成モデルは教師あり学習しかできない", "識別モデルの方がパラメータ数が多い", "生成モデルは画像専用である"],
            answer: 0,
            explanation: "生成モデルは「データがどのように発生したか」という分布そのものをモデリングするため、そこから新しいサンプリング（生成）が可能です。"
        },
        {
            category: "VAEの構造",
            question: "VAE（変分オートエンコーダ）が、通常のオートエンコーダと決定的に異なる点は何か。",
            options: ["潜在変数 $z$ を固定値ではなく「確率分布（平均と分散）」として扱う", "エンコーダが存在しない", "デコーダが存在しない", "入力と出力が異なるデータである"],
            answer: 0,
            explanation: "データを一点に圧縮するのではなく、「このあたりにあるはず」という分布（ガウス分布）に変換することで、未知のデータを生成できるようにしています。"
        },
        {
            category: "GANの構造",
            question: "GAN（敵対的生成ネットワーク）を構成する2つのネットワークの役割は何か。",
            options: ["Generator（生成器）は偽造データを作り、Discriminator（識別器）は真贋を見抜く", "Generatorは画像を圧縮し、Discriminatorは復元する", "Generatorはノイズを除去し、Discriminatorはノイズを加える", "両方とも画像を分類する"],
            answer: 0,
            explanation: "「偽札作り」と「警察」のいたちごっこに例えられます。互いに競い合うことで精度を高めていきます。"
        },
        {
            category: "Reparameterization Trick",
            question: "VAEにおいて、学習時に「Reparameterization Trick」が必要になる理由は何か。",
            options: ["確率的なサンプリング操作が含まれると、そこで微分ができず誤差逆伝播がストップしてしまうため", "計算速度を上げるため", "潜在変数の次元を減らすため", "過学習を防ぐため"],
            answer: 0,
            explanation: "確率分布からのランダムな「サンプリング」は微分不可能です。そこで $z = \\mu + \\sigma \\odot \\epsilon$ （$\\epsilon$は乱数）と書き換えることで、$\\mu$ と $\\sigma$ で微分可能にします。"
        },
        {
            category: "モード崩壊",
            question: "GANの学習における失敗例「モード崩壊 (Mode Collapse)」とはどのような現象か。",
            options: ["Generatorが、Discriminatorを騙しやすい特定のパターンの画像（似たような画像）ばかりを生成するようになる現象", "画像がノイズだらけになる現象", "Discriminatorが強くなりすぎて学習が止まる現象", "Generatorが真っ白な画像を生成する現象"],
            answer: 0,
            explanation: "「この絵を出せば騙せる！」と味を占めてしまい、多様性が失われた状態です（例：どんな入力を入れても「数字の1」しか出なくなる）。"
        },
        {
            category: "拡散モデル",
            question: "近年注目されている「拡散モデル (Diffusion Model)」の基本的な生成プロセスはどれか。",
            options: ["完全なノイズ画像からスタートし、徐々にノイズを除去して意味のある画像を復元する", "潜在変数をGANで生成する", "画像をパッチに分割して並べ替える", "画像を圧縮して解凍する"],
            answer: 0,
            explanation: "インクが水に拡散して消えていく過程（順方向）を学習し、逆に時間を巻き戻してインクを復元する（逆方向）イメージです。"
        },
        {
            category: "VAEの損失関数",
            question: "VAEの損失関数（変分下限 / ELBO）は、「再構成誤差」と、もう一つ何の和で構成されるか。",
            options: ["KLダイバージェンス（正則化項）", "敵対的損失", "L1正則化項", "ドロップアウト項"],
            answer: 0,
            explanation: "潜在変数の分布 $q(z|x)$ が、事前分布 $p(z)$（通常は標準正規分布）に近づくように制約をかける項（KL項）が必要です。"
        },
        {
            category: "GANの目的関数",
            question: "GANの学習は、数学的にはどのような問題として定式化されるか。",
            options: ["ミニマックス（Minimax）問題", "最大化問題", "最小二乗法", "線形計画問題"],
            answer: 0,
            explanation: "Generatorは損失を最小化したい、Discriminatorは損失（見破る確率）を最大化したい、というサドルポイント探索問題になります。"
        },
        {
            category: "条件付きGAN",
            question: "「Conditional GAN (cGAN)」の特徴は何か。",
            options: ["生成時に「クラスラベル」などの条件を与えることで、生成する画像の種類を指定できる", "条件を満たすまで学習を繰り返す", "特定の条件でのみ動作する", "条件分岐を含むネットワークである"],
            answer: 0,
            explanation: "通常のGANはランダムなノイズから生成するため何が出るか制御できませんが、cGANはラベル（例：「犬」）も入力することで出力を制御できます。"
        },
        {
            category: "オートエンコーダ",
            question: "オートエンコーダにおいて、入力層よりも中間層（潜在変数）の次元を小さくする理由として適切なものはどれか。",
            options: ["重要な特徴量だけを抽出（次元圧縮）し、ノイズを除去するため", "計算を速くするためだけ", "入力を暗号化するため", "画像を拡大するため"],
            answer: 0,
            explanation: "ボトルネック（くびれ）を作ることで、ネットワークは無理やり情報を圧縮しなければならなくなり、結果としてデータの本質的な特徴を獲得します。"
        },

        // ---------------------------------------------------------
        // 【応用編】 Q11 - Q20
        // ---------------------------------------------------------
        {
            category: "Reparameterization(応用)",
            question: "VAEのReparameterization Trickの式 $z = \\mu + \\sigma \\odot \\epsilon$ において、$\\epsilon$ は通常どのような分布からサンプリングされるか。",
            options: ["標準正規分布 $N(0, 1)$", "一様分布", "ベルヌーイ分布", "ポアソン分布"],
            answer: 0,
            explanation: "平均0、分散1の正規分布からノイズ $\\epsilon$ を取り、それに分散 $\\sigma$ を掛けて平均 $\\mu$ を足すことで、任意のガウス分布を作ります。"
        },
        {
            category: "GANの勾配消失(応用)",
            question: "GANの学習初期において、Discriminatorが強すぎると（完璧に見破れるようになると）Generatorの学習が進まなくなる理由は何か。",
            options: ["Discriminatorによる判定が完璧（確率1.0か0.0）になると、勾配が消失してGeneratorがどう改善すればいいか分からなくなるため", "Generatorが諦めてしまうから", "モード崩壊が起きるから", "過学習するから"],
            answer: 0,
            explanation: "シグモイド関数の両端（0や1付近）は微分値がほぼ0です。Dが圧勝するとGに伝わる勾配がなくなります。これを防ぐためにWasserstein GANなどが提案されました。"
        },
        {
            category: "Pix2Pix(応用)",
            question: "「線画をカラー写真に変換する」など、ペアとなる画像データがある場合の画像変換に使われるGANモデルはどれか。",
            options: ["Pix2Pix", "CycleGAN", "StyleGAN", "DCGAN"],
            answer: 0,
            explanation: "入力画像と正解画像のペアを使って、cGANの一種として学習します。"
        },
        {
            category: "CycleGAN(応用)",
            question: "「馬の画像をシマウマに変換する」など、ペアとなる正解画像が存在しないデータセットでも学習できるモデルはどれか。",
            options: ["CycleGAN", "Pix2Pix", "VGG", "ResNet"],
            answer: 0,
            explanation: "「馬→シマウマ→馬」と変換して元に戻るか（サイクル一貫性損失）を制約にすることで、ペア画像なしでのスタイル変換を可能にしました。"
        },
        {
            category: "WGAN(応用)",
            question: "Wasserstein GAN (WGAN) が導入した「Wasserstein距離（Earth Mover's Distance）」のメリットは何か。",
            options: ["分布同士が重なっていなくても距離を測れるため、勾配消失しにくく学習が安定する", "計算が非常に高速である", "画像が鮮明になる", "モード崩壊を完全に防げる"],
            answer: 0,
            explanation: "従来のJSダイバージェンスなどは分布が重なっていないと値が定数になり勾配が消えましたが、EM距離は離れていても「どれくらい離れているか」という勾配を持ちます。"
        },
        {
            category: "VAE vs GAN(応用)",
            question: "一般的に、VAEとGANが生成する画像の特徴的な違い（画質面）は何か。",
            options: ["VAEは全体的に「ぼやけた」画像になりやすく、GANは「くっきり」した画像になりやすい", "VAEは鮮明だがノイズが多く、GANは滑らか", "VAEは白黒、GANはカラー", "違いはない"],
            answer: 0,
            explanation: "VAEは分布の平均（期待値）を出そうとするため、細部が平均化されてぼやける傾向があります。GANは識別器を騙そうとするため、細部までリアルな（鋭い）画像を作ります。"
        },
        {
            category: "フローベース生成モデル(応用)",
            question: "「Flow-based生成モデル（Glowなど）」の最大の特徴でありメリットは何か。",
            options: ["変数変換のヤコビアンを用いて、尤度（Likelihood）を厳密に計算でき、かつ可逆（Invertible）である", "計算量が最も少ない", "圧縮率が最も高い", "離散データに特化している"],
            answer: 0,
            explanation: "VAEは下限の近似、GANは尤度計算不可ですが、Flowモデルは可逆関数を重ねることで尤度を直接最大化でき、潜在変数と画像を1対1で行き来できます。"
        },
        {
            category: "拡散モデルの欠点(応用)",
            question: "高品質な画像を生成できる拡散モデルだが、GANと比較した際の主なデメリットは何か。",
            options: ["生成（推論）にかかる時間が長い（何回もノイズ除去ステップを踏む必要があるため）", "学習が不安定", "多様性がない", "モデルサイズが小さい"],
            answer: 0,
            explanation: "ノイズ除去プロセスを数百〜千回繰り返す必要があるため、1枚の生成に時間がかかります（これを高速化する研究がLatent Diffusionなどです）。"
        },
        {
            category: "DCGAN(応用)",
            question: "初期のGANを安定化させた「DCGAN」が導入した構造上の工夫として正しいものはどれか。",
            options: ["全結合層を廃止して畳み込み層（CNN）を使用し、Batch NormalizationやLeaky ReLUを採用した", "層を非常に深くした", "Transformerを導入した", "Dropoutを多用した"],
            answer: 0,
            explanation: "それまで全結合層メインで不安定だったGANに、CNNのアーキテクチャやBatchNormを適切に組み込み、画像生成の標準形を作りました。"
        },
        {
            category: "StyleGAN(応用)",
            question: "高解像度でリアルな顔画像を生成できる「StyleGAN」の特徴的な入力方法はどれか。",
            options: ["潜在変数 $z$ を直接入力せず、Mapping Networkを通してスタイル情報 $w$ に変換し、各層にAdaINで注入する", "画像をパッチに分割して入力する", "ノイズを入力せず、画像のみを入力する", "3Dモデルを入力する"],
            answer: 0,
            explanation: "従来の「入力層にノイズを入れる」方式をやめ、スタイル（髪型、肌の色など）を制御する情報を各階層に流し込むことで、高度な制御と画質を実現しました。"
        }
    ]
};
