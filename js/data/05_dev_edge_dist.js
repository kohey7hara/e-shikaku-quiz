window.quizData = {
    title: "5-（１）（２）エッジAI & 分散処理",
    
    cheatSheet: `
        <h3>■ モデルの軽量化技術</h3>
        <p>エッジデバイス（スマホやIoT）で動かすための技術。</p>
        <table>
            <tr><th>手法</th><th>概要</th></tr>
            <tr><td><strong>蒸留 (Distillation)</strong></td><td>巨大な<strong>教師モデル</strong>の知識を、軽量な<strong>生徒モデル</strong>に継承させる。<br>「温度付きSoftmax」で確率分布（Soft target）を真似る。</td></tr>
            <tr><td><strong>量子化 (Quantization)</strong></td><td>パラメータの精度（ビット数）を落とす。<br>例：32bit浮動小数点(FP32) → 8bit整数(INT8)。<br>サイズは1/4になり、計算も高速化する。</td></tr>
            <tr><td><strong>プルーニング (Pruning)</strong></td><td>寄与度の低い（0に近い）ニューロンや結合を削除する（枝刈り）。<br>モデルがスカスカ（スパース）になる。</td></tr>
        </table>

        <h3>■ 並列分散処理</h3>
        <table>
            <tr><th>手法</th><th>概要</th></tr>
            <tr><td><strong>データ並列</strong></td><td>各GPUに<strong>同じモデル</strong>をコピーし、<strong>異なるデータ</strong>を流す。<br>勾配を集計してパラメータを同期する（AllReduce）。主流の手法。</td></tr>
            <tr><td><strong>モデル並列</strong></td><td>巨大なモデルを分割し、<strong>異なるGPU</strong>に配置する。<br>1つのGPUに乗り切らない巨大モデルで使用。</td></tr>
        </table>
    `,

    questions: [
        // ---------------------------------------------------------
        // 【基礎編】 Q1 - Q10
        // ---------------------------------------------------------
        {
            category: "蒸留",
            question: "「知識の蒸留 (Knowledge Distillation)」において、知識を教える側と教わる側のモデルの組み合わせとして正しい呼称はどれか。",
            options: ["教師モデル (Teacher) と 生徒モデル (Student)", "親モデル (Parent) と 子モデル (Child)", "サーバーモデル (Server) と クライアントモデル (Client)", "エンコーダ (Encoder) と デコーダ (Decoder)"],
            answer: 0,
            explanation: "高精度だが巨大な「教師」の出力を正解として、軽量な「生徒」に学習させます。"
        },
        {
            category: "量子化",
            question: "モデルの重みを「FP32（32ビット浮動小数点）」から「INT8（8ビット整数）」に変換する手法を何と呼ぶか。",
            options: ["量子化 (Quantization)", "蒸留 (Distillation)", "プルーニング (Pruning)", "正規化 (Normalization)"],
            answer: 0,
            explanation: "表現できる情報量は減りますが、モデルサイズを劇的に小さくし、推論速度を向上させることができます。"
        },
        {
            category: "プルーニング",
            question: "プルーニング（枝刈り）において、一般的に削除対象となる重み（パラメータ）はどのようなものか。",
            options: ["絶対値が0に近い（重要度が低い）重み", "絶対値が大きい重み", "ランダムに選ばれた重み", "プラスの値を持つ重み"],
            answer: 0,
            explanation: "出力にほとんど影響を与えない「0に近い重み」を削除（0に固定）することで、精度を保ったまま計算量を削減します。"
        },
        {
            category: "エッジコンピューティング",
            question: "クラウドではなく、ユーザーに近い場所（端末側）でAIの推論処理を行う「エッジコンピューティング」のメリットとして、**誤っている**ものはどれか。",
            options: ["クラウドサーバーよりも計算能力が圧倒的に高い", "通信遅延（レイテンシ）が少ないためリアルタイム処理に向いている", "データを外部に出さないためプライバシー保護に優れている", "オフラインでも動作する"],
            answer: 0,
            explanation: "エッジデバイス（スマホやIoT機器）は、クラウドの巨大サーバーに比べると計算リソースや電力に厳しい制約があります。だからこそ軽量化が必要です。"
        },
        {
            category: "データ並列",
            question: "「データ並列化」による分散学習の説明として正しいものはどれか。",
            options: ["各ワーカー（GPU）がモデルのコピーを持ち、異なるミニバッチデータを処理して、勾配を共有・同期する", "モデルを分割して各ワーカーに配置し、同じデータを順番に処理する", "ハイパーパラメータを分割して探索する", "異なるモデル構造を同時に学習させる"],
            answer: 0,
            explanation: "最も一般的な分散学習手法です。全員で手分けしてデータを消化し、学習結果（勾配）を「せーの」で持ち寄ってモデルを更新します。"
        },
        {
            category: "モデル並列",
            question: "「モデル並列化」が不可欠となるケースはどれか。",
            options: ["モデルのサイズが巨大すぎて、1つのGPUメモリに収まりきらない場合", "学習データが非常に少ない場合", "通信速度が非常に速い場合", "CPUしか使えない場合"],
            answer: 0,
            explanation: "GPT-3のような超巨大モデルは1枚のGPUに乗らないため、層ごとに分割して複数のGPUに配置する必要があります。"
        },
        {
            category: "同期型 vs 非同期型",
            question: "分散学習における「同期型（Synchronous）」の特徴として正しいものはどれか。",
            options: ["全てのワーカーの計算が終わるのを待ってから、一斉にパラメータを更新する", "計算が終わったワーカーから順次パラメータを更新する", "ワーカー間で通信を行わない", "精度が不安定になりやすい"],
            answer: 0,
            explanation: "待つ時間（待ち合わせ）が発生しますが、単一GPUでの学習と数学的に等価になるため、学習が安定して高精度になりやすいです。"
        },
        {
            category: "Soft target",
            question: "蒸留において、教師モデルが出力する確率分布（例：[犬:0.7, 猫:0.2, 鳥:0.1]）のことを何と呼ぶか。",
            options: ["ソフトターゲット (Soft target)", "ハードターゲット (Hard target)", "ワンホットベクトル (One-hot vector)", "グランドトゥルース (Ground truth)"],
            answer: 0,
            explanation: "正解ラベル（Hard target: [1, 0, 0]）よりも、「猫っぽさも少しある」といった豊富な情報を含んでいるため、生徒モデルの学習に役立ちます。"
        },
        {
            category: "IoTデバイス",
            question: "IoTデバイスでディープラーニングを行う際の、主な制約条件（ボトルネック）とならないものはどれか。",
            options: ["利用可能な学習データの総量", "消費電力（バッテリー）", "メモリ容量", "放熱（発熱）"],
            answer: 0,
            explanation: "学習データ自体はクラウドなどで管理できますが、デバイス上で推論する際の「電力・メモリ・熱」は物理的な制約となります。"
        },
        {
            category: "パラメータ共有サーバー",
            question: "分散学習において、各ワーカーから勾配を集めてパラメータを管理・更新する役割を持つノードを何と呼ぶか。",
            options: ["パラメータサーバー (Parameter Server)", "ワーカーノード", "エッジサーバー", "コンテナ"],
            answer: 0,
            explanation: "各ワーカーは計算だけ担当し、パラメータサーバーが更新を担当する構成です（AllReduce方式ではサーバーを置かないこともあります）。"
        },

        // ---------------------------------------------------------
        // 【応用編】 Q11 - Q20
        // ---------------------------------------------------------
        {
            category: "蒸留の温度(応用)",
            question: "蒸留で用いられる「温度パラメータ $T$」を高く設定する（$T > 1$）と、Softmax関数の出力はどう変化するか。",
            options: ["確率分布が平滑化され（なだらかになり）、小さな確率の値も強調されるようになる", "確率分布がより尖鋭化され（ピークが鋭くなり）、最大値以外は0に近づく", "確率分布の合計が1を超えてしまう", "ランダムな値になる"],
            answer: 0,
            explanation: "温度を上げると分布がマイルドになり、「正解以外のクラスの情報（暗黙の知識）」が生徒に伝わりやすくなります。"
        },
        {
            category: "量子化の影響(応用)",
            question: "「量子化アウェア学習 (Quantization Aware Training)」とはどのような手法か。",
            options: ["学習中から量子化による精度の劣化をシミュレーション（考慮）して学習を行い、推論時の精度低下を防ぐ手法", "学習完了後に単にビット数を落とす手法", "量子コンピュータを使って学習する手法", "量子化誤差を無視する手法"],
            answer: 0,
            explanation: "単なる事後量子化（Post-training Quantization）では精度が落ちる場合、学習段階で「量子化したらこうなる」というノイズを含ませて訓練します。"
        },
        {
            category: "AllReduce(応用)",
            question: "データ並列分散学習において、全GPUが持つ勾配の合計を計算し、その結果を再び全GPUに配る通信アルゴリズムを何と呼ぶか。",
            options: ["AllReduce", "Broadcast", "Scatter", "Gather"],
            answer: 0,
            explanation: "Ring AllReduceなどが有名です。パラメータサーバーを介さずに、GPU同士がバケツリレー式にデータを交換して効率よく同期します。"
        },
        {
            category: "スパース性(応用)",
            question: "プルーニングによってモデルの重み行列が「スパース（疎）」になった場合、計算速度を向上させるために必要なものは何か。",
            options: ["スパース行列演算に対応した専用のハードウェアやライブラリ", "より高速なCPU", "より多くのメモリ", "高解像度の入力画像"],
            answer: 0,
            explanation: "単に0が増えただけでは、通常の行列演算を行うと0×何かを計算し続けるため速くなりません。0を飛ばして計算する仕組みが必要です。"
        },
        {
            category: "MobileNet(応用)",
            question: "エッジデバイス向けに設計された「MobileNet」が、計算量を減らすために採用した特殊な畳み込みはどれか。",
            options: ["Depthwise Separable Convolution", "Dilated Convolution", "Transposed Convolution", "Deformable Convolution"],
            answer: 0,
            explanation: "通常の畳み込みを「Depthwise（空間方向）」と「Pointwise（チャンネル方向）」に分解することで、パラメータ数と計算量を劇的に削減しました。"
        },
        {
            category: "非同期型の欠点(応用)",
            question: "非同期型の分散学習において発生しやすい「Stale Gradients（古くなった勾配）」問題とは何か。",
            options: ["遅いワーカーが計算している間にパラメータが更新されてしまい、古いパラメータに基づいた勾配を適用することで学習が不安定になる問題", "勾配が消失して0になる問題", "勾配が爆発する問題", "メモリリークが発生する問題"],
            answer: 0,
            explanation: "「浦島太郎」状態のワーカーが、古い地図（パラメータ）で計算した移動方向（勾配）を持ち込んでくるため、全体として間違った方向に進むリスクがあります。"
        },
        {
            category: "混合精度学習(応用)",
            question: "「混合精度学習 (Mixed Precision Training)」の主なメリットは何か。",
            options: ["FP16（半精度）とFP32（単精度）を使い分けることで、計算速度の向上とメモリ使用量の削減を両立する", "精度を犠牲にして速度だけを追求する", "量子化と同じくINT8のみを使って計算する", "学習率を自動調整する"],
            answer: 0,
            explanation: "計算の大部分は高速なFP16で行い、勾配の足し合わせなど精度が必要な部分だけFP32に残すことで、精度を落とさずに高速化します。"
        },
        {
            category: "連合学習(応用)",
            question: "プライバシー保護の観点で注目される「連合学習 (Federated Learning)」の特徴はどれか。",
            options: ["データをサーバーに集めず、各エッジデバイスで学習を行い、学習した「重みの更新量（勾配）」だけをサーバーに送る", "データを全てサーバーに集めてから暗号化して学習する", "サーバーを使わずにエッジ同士だけで通信する", "学習を行わずに推論だけを行う"],
            answer: 0,
            explanation: "「データは動かさず、モデル（重み）を動かす」アプローチです。個人のスマホ内のデータを外に出さずに、全体のモデルを賢くできます。"
        },
        {
            category: "エッジAIチップ(応用)",
            question: "Googleの「Edge TPU」やNVIDIAの「Jetson」などが搭載している、ディープラーニング推論に特化したプロセッサを一般に何と呼ぶか。",
            options: ["NPU (Neural Processing Unit) / AIアクセラレータ", "CPU", "FPGA", "Micro Controller"],
            answer: 0,
            explanation: "行列演算（積和演算）に特化した回路を持ち、低電力で高速な推論を実現するチップです。"
        },
        {
            category: "バイナリニューラルネット(応用)",
            question: "究極の量子化とも言える「Binary Neural Network (BNN)」では、重みや活性化値を何ビットで表現するか。",
            options: ["1ビット (-1 と +1)", "2ビット", "4ビット", "8ビット"],
            answer: 0,
            explanation: "情報を極限まで削ぎ落とし、値の「符号」だけで計算します。積和演算が論理演算（XNORなど）に置き換わるため超高速ですが、精度維持が課題です。"
        }
    ]
};
